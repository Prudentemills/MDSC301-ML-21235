{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Review Questions-I from MDSC-301(P) Assignment\n",
    "\n",
    "----------------------------------------------------------------\n",
    "Author: Parth\n",
    "\n",
    "Date: September 7, 2022\n",
    "\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q1. Which Linear Regression training algorithm can you use if you have\n",
    "a training set with millions of features?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1. If there are millions of features, we depend on the Variations of gradient techniques which can give reliable results for minimizing the loss function.  \n",
    "1. Batch Gradient Descent  \n",
    "1. Stochastic Gradient Descent  \n",
    "3. Mini-Batch Gradient\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2. Suppose the features in your training set have very different scales.\n",
    "Which algorithms might suffer from this, and how? What can you\n",
    "do about it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2. This will affect the Gradient algorithms because different scaling could elongate the bowl shape curve and also the computation time. Either scaling the features or increasing learning rate will help. Normal equations will not suffer highly.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.  Suppose you use Batch Gradient Descent and you plot the validation\n",
    "error at every epoch. If you notice that the validation error\n",
    "consistently goes up, what is likely going on? How can you fix this?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3. This means we have set-up higher learning rate for the algorithms and it's diverging it to other points. And Also training error goes up,  Decreasing the Alpha i.e. learning rate should work. If Training rate isn't going up, model may be overfitting and we can stop training for regularizing data.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4. Is it a good idea to stop Mini-batch Gradient Descent immediately\n",
    "when the validation error goes up?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A4. __NO__. Mini batches consists of randomly selected examples and it may be possible to get validation error high. We only tend to stop the algorithm if no changes are seen for long time.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5. Suppose you are using Polynomial Regression. You plot the learning\n",
    "curves and you notice that there is a large gap between the training\n",
    "error and the validation error. What is happening? What are three\n",
    "ways to solve this?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A5. THe \"gap\" is calle doverfitting if the training error is less and validation error piles up. We can do few things to control it.\n",
    "1. Regaularizaton with L1(Lasso regression) or L2(Ridge Regression)\n",
    "2. Reduce the polynomial degree or the complexity of the model with reducing features\n",
    "3. feeding more training data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6. Suppose you are using Ridge Regression and you notice that the\n",
    "training error and the validation error are almost equal and fairly\n",
    "high. Would you say that the model suffers from high bias or high\n",
    "variance? Should you increase the regularization hyperparameter $\\alpha$\n",
    "or reduce it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A6. When Validation and Training errors are found to be high and almost equal, we can sense that bias is high and thus, model is underfitting the model [ *from error vs model complexity* ]. We should be reducing  the hyperparamter $\\alpha$.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q7. Why would you want to use:__\n",
    "   - Ridge Regression instead of plain Linear Regression (i.e., without any regularization)?\n",
    "   - Lasso instead of Ridge Regression?\n",
    "   - Elastic Net instead of Lasso?\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A7. \n",
    "-  A model with perform with some regularization as it try to keep check on bias-Variance trade off. A simple model like linear regression will have limitations for any more changes apart from decreasing complexity in model.\n",
    "- Lasso will give upperhand by providing the method to perform automatic feature selection by dropping weights of most important features. It is able to force the coeffiecents to zero which can't be done in ridge regularization.\n",
    "- Elastic Net gives profits of both Lasso and ridge, making it more efficient. It's predicitve power is better than lasso, while still performing feature selection. \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.  Can you name four of the main challenges in Machine Learning?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A8. Any Machine Learning algorithm highly depends on the data we provide in amount and quality and the computation power limitation becomes the challange. It also could be with feature we select for the problme.\n",
    "Four main challanges :-\n",
    "- Quality of data\n",
    "- Insufficiency of data\n",
    "- Non-Representative training data : It should give the accurate picture of population. All should be handle in sampling where lack of data or wromg technique can lead to flawed training data, also introducing bias-variance trade off.\n",
    "- Irrevelant Features\n",
    "- Under and Over fitting of Data\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9. If your model performs great on the training data but generalizes\n",
    "poorly to new instances, what is happening? Can you name three\n",
    "possible solutions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A9. Overfitting of data can be observed in such scenario as it's giving poor result on test dataset. We can look for few helps such as:\n",
    "1. feeding more training Data\n",
    "1. regualrization [L1 or L2]\n",
    "1. Cross validation\n",
    "1. Dimensionality reduction [dropping features or reducing complexity of model]\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10. What is a test set, and why would you want to use it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A10. Test dataset is build of unseen datapoints taken from original dataset apart from training dataset to check the accuracy of model after the training and know the model performance overall.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.  What is the purpose of a validation set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A11. Validation dataset is taken from training dataset and model is checked on this after every epoch to give the unbiased evaluation of model which can help to early stop of training and tuning the hyperparamaters.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12. What are different loss functions? Exaplain their importance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A12. Different Loss functions:\n",
    "1. Mean Squared Error \n",
    "    - $ MSE = \\frac{1}{n}\\sum_{i=1}^{n} (y_i-\\hat{y}_i)^2$\n",
    "    - Higher errors are penalized heavily than the smaller errors. Being a differential function, it is easier to calculate gradients.\n",
    "    \n",
    "  \n",
    "  \n",
    "2. Root Mean Squared Error \n",
    "    * $RMSE = \\sqrt{MSE}$\n",
    "    * Brings MSE to the same units of data under analysis.\n",
    "    \n",
    "  \n",
    "  \n",
    "3. Mean Absolute Error \n",
    "    * $MAE = \\frac{1}{n}\\sum_{i=1}^{n} |y_i-\\hat{y}_i|$\n",
    "    * preserves the same units of measurement as the data under analysis. MAE scores increases linearly with increases in errors and thus is much more interpretable than MSE.\n",
    "    \n",
    "  \n",
    "4. Hinge Loss \n",
    "    * $Hinge Loss = max(0, 1- y\\cdot\\hat{y})$\n",
    "    * It is most commonly employed to regularize soft margin support vector machines. \n",
    "    \n",
    "  \n",
    "  \n",
    "5. Logistic/Cross Entropy Loss \n",
    "    * leads to better probability estimation at the cost of accuracy.\n",
    "    * $L = -\\frac{1}{n} \\sum_{i=1}^{n} y_i \\cdot log(\\hat{y_i})$\n",
    "\n",
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13. Explain the following:\n",
    "    - Gradient descent\n",
    "    - Mini-batch gradient descent\n",
    "    - Batch gradient, and\n",
    "    - Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A13. \n",
    "> **Batch Gradient Descent :**\n",
    ">> Averaging over all the gradients of training data for a single step. The training data is taken into consideration to take a single step. and then, averaged or mean gradient is used to update the parameters. This will give a smoothen curve later for __cost vs epoch__ graph because we are taking mean gradient in each epoch.\n",
    "***\n",
    "> **Stochastic Gradient Descent :**\n",
    ">> More the data, better the model. If data is on large scale, it's difficult to implement Batch Gradient descent. Here comes, Stochastic Gradient Descent or SGD. It will take single example in single epoch. This will be done for all the examples but randomly and weights will be updated simulanteously. The cost curve will fluctuate as it need not decrease everytime but will be good in long run.\n",
    "Run faster for Larger Datasets.\n",
    "***\n",
    "> **Mini Batch Gradient :**\n",
    ">> BGD runs smoothly for smaller datasets and converges to minima whereas SGD works good for larger datasets but vectorization can't be implemented as  it takes single output at a time. Thus we define mini-batches of fixed sizes which give advantages of both the variants.  \n",
    "Each epoch will train on mini-batch and calculate mean gradient and update the weights.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14. What is learning rate?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A14. Learning rate is hyperparameter to be tuned in optimisation technique while finding minimum of a loss function in gradient descent algorithms. It is step size to be taken in each iteration. \n",
    "- Higher the $\\alpha$, higher chance of missing minima. \n",
    "- Lower the $\\alpha$, more the computation time\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15. Define the following terms. Explain their importance in the data analysis.**\n",
    "   - $R^2$\n",
    "   - Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A15. \n",
    "> $R^2$ :\n",
    ">> It's statistical measure to represnt the proportion of the variance for a dependent variable that's explanied by an indepenedent variable or variables in a regression model. few regressors addition, and it will increase no matter what the contribution. That's where we get Adj. $R^2$\n",
    ">>> $R^2 = 1 - \\frac{RSS}{TSS}$\n",
    "***\n",
    "> $Adjusted R^2$ :\n",
    ">> It will add the penalty to the accuracy for those dummy variables who are not contibuting in the model significantly. We can observe with both that how the model is actually performing.\n",
    ">>>$Adj. R^2 = 1- \\frac{RSS/(n-k)}{TSS/(n-1)}$\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16. Explain One-Hot Encoding and Label Encoding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A16. Encoding techniques are used in order to deal with categorical features present in the dataset. We can convert them into some numbers using their inherit order or ordinal order.\n",
    "> One-Hot Encoding:\n",
    ">> It is used for nominal ordered features which has no ordering sense but has different classes. It will add features equal to the classes present in the features. this will add dummy variables in the dataset.\n",
    "***\n",
    "> Label Encoding:\n",
    ">> It can used for ordinal categorical features which has specific inherit ordering sense. We can simply provide numbers to all classes present. \n",
    "Also known as Integer Encoding\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17. What are the assumption on Naive Bayes algorithm in classification?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A17. The Naive Bayes assumptions:\n",
    "\n",
    "- The prior probabilities for each class is either uniform or empirical\n",
    "- The likelihood probabilities are Gaussian.\n",
    "- All the features (or predictors) are independent.Thus p-dimensional class-conditional distributions can be factorised into a product of p univariate distributions.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18. What is the difference between classification and regression?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A18. The differences are basically on the approches taken and the target variable defined.\n",
    "> __Classification :__ When the regressand is categorical variable and we need to classify based on the probablities of all classes present in it, classfications algorithms will soar. IT can also be seen as mapping function. It works well on unsupervised data.\n",
    "\n",
    "> __Regression :__ It predicts the best approximated continuous output value based on the features given as input.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q19. How to ensure that the model is not overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A19. There are several ways to resolve the overfitting in the model.\n",
    "- Data Augmentation\n",
    "- Splitting the data into test and validation dataset\n",
    "- Decreasing the complexity by dropping features\n",
    "- Adding more training Data\n",
    "- K-fold cross validation\n",
    "- Feature Selection\n",
    "- Regularization - L1 or L2\n",
    "- Early Stopping after validation and training errors rises.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q20. List the main advantage of Naive Bayes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A20.\n",
    "1. It uses Bayesian technique and thus does not require much training data\n",
    "2. It's works quickly and can save a lot of time and suitable for solving multi-class prediction problems\n",
    "3. If the independence of features holds true, Navie Bayes can perform better than other models\n",
    "4. It's better suited for categorical predictors than numerical variables\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q21. What you should do when your model is suffereing from:  \n",
    "    - Low bias and high variance?  \n",
    "    - High bias and low variance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A21.   \n",
    "*Low Bias and High Variance:*\n",
    "\n",
    "   - Models that overfit have low bias and high variance.\n",
    "   - We can reduce the complexity of the model to get a good bias-variance trade off\n",
    "   - We can remove irrelevant features from the model.\n",
    "   - We can use Regularization techniques to reduce overfitting.\n",
    "   - We can add more training data to prevent overfitting.\n",
    "   - Decreasing the degree of the polynomial  of the hypothesis function is another approach to solve the problem.\n",
    "   \n",
    "*High Bias and Low Variance:*\n",
    "\n",
    "   - Models that underfit have high bias and low variance.\n",
    "   - It is usually caused when the hypothesis function is too simple or has very less features.\n",
    "   - We can increase the number of features to overcome this.\n",
    "   - We can also do feature engineering.\n",
    "   - Increasing the degree of the polynomial  of the hypothesis function is another approach to solve the problem.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q22. What is the 'Naive' in the Naive Bayes Classifier?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A22. Naive Bayes Classifier is 'naive' because it makes the assumption that features of a measurement are independent of each other and it almsot never true.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q23. What is bias-variance tradeoff in Machine Learning ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A23. Bias-Variance falls under the category of reducible errors which can be scale down with regularization. This trade off often happens in ML models, thus make it popular.  \n",
    "Bias can be because of imbalance data where model is not able recognise or underestimating a class completely. Also Variance can vary with model generalisation on training dataset and performance on test dataset.\n",
    "- If the model is too simple and few params, then model will have High Bias and Low Variance.\n",
    "- If the model is too complex with many params, then model will have low low Bias but High Variance.  \n",
    "\n",
    "    **OUR AIM : LOW BIAS AND LOW VARIANCE**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q24. Explain different trade-offs in Machine Learning algorithms?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A23. Types of Trade-offs :\n",
    "1. BIAS - VARIANCE TRADE OFF\n",
    "2. PRECISION - RECALL TRADE OFF\n",
    "3. INTERPRETABILITY - COMPLEXITY TRADE OFF\n",
    "4. PRIVACY - FAIRENESS TRADE OFF\n",
    "5. ACCURACY - INTERPRETABILITY TRADE OFF\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q25. What is cross-validation and how it is useful in traing ML models?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A25. Cross validation is method to overcome the overfitting and evaluate the performace of model after epoch for early stopping of training if required.  \n",
    "     Dataset is broken into three sets: training, test and validation which will be taken from train set itself.\n",
    "> K-fold Cross Validation:\n",
    ">> This method willbreak the training set into K-sets. In $i^th$ epoch, $i^th$ set will be reserved for validation and k-{$i^th$} sets will be trained on. This will surely gives the better results as model will start performing with each iteration. $i^th$ set is called Hold-out set. \n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
